<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ChatGPT Prompt Engineering for Developers</title>
<meta name="author" content="dirtysalt" />
<meta name="generator" content="Org Mode" />
<link rel="shortcut icon" href="/themes/favicon.ico" /><link rel="stylesheet" type="text/css" href="/themes/simple.css"/></head>
<body>
<div id="content" class="content">
<h1 class="title">ChatGPT Prompt Engineering for Developers</h1>
<p>
花了点时间看了一下这门课程 <a href="https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction">DLAI - Learning Platform Prototype</a> 难度不是很大，感觉非常值得，总之就是教你怎么写prompt.
</p>

<p>
归纳下来大概是这么几个场景：
</p>
<ol class="org-ol">
<li>summarizing. 比如总结文字的内容，或者从中抽取信息</li>
<li>inferring. 比如推理出文字中的情绪，或者是推理出其中的主题</li>
<li>transforming. 比如翻译一段话，并且能加入情绪和场景信息</li>
<li>expanding. 比如根据一段话如何生成回复</li>
<li>chatbot. 多轮交互，并且可以设置背景</li>
</ol>

<p>
另外看了一下openai doc网站，里面写到了如何计算token一些基本问题。<a href="https://platform.openai.com/docs/introduction/overview">Introduction - OpenAI API</a>
</p>

<blockquote>
<p>
The number of tokens processed in a given API request depends on the length of both your inputs and outputs. As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text. One limitation to keep in mind is that your text prompt and generated completion combined must be no more than the model's maximum context length (for most models this is 2048 tokens, or about 1500 words). Check out our tokenizer tool to learn more about how text translates to tokens.
</p>
</blockquote>

<p>
关于各种模型区别和解释 <a href="https://platform.openai.com/docs/models">Models - OpenAI API</a>
</p>

<hr />

<p>
通用代码
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-py-import-from">import</span> openai
<span class="org-py-import-from">import</span> os

<span class="org-py-import-from">from</span> dotenv <span class="org-py-import-from">import</span> load_dotenv, find_dotenv
<span class="org-py-builtins">_</span> = load_dotenv(find_dotenv())

<span class="org-py-variable-name">openai.api_key</span>  = os.getenv(<span class="org-string">'OPENAI_API_KEY'</span>)

<span class="org-py-def-class">def</span> <span class="org-function-name">get_completion</span>(prompt, <span class="org-py-variable-name">model</span>=<span class="org-string">"gpt-3.5-turbo"</span>):
    <span class="org-py-variable-name">messages</span> = [{<span class="org-string">"role"</span>: <span class="org-string">"user"</span>, <span class="org-string">"content"</span>: prompt}]
    <span class="org-py-variable-name">response</span> = openai.ChatCompletion.create(
        <span class="org-py-variable-name">model</span>=model,
        <span class="org-py-variable-name">messages</span>=messages,
        <span class="org-py-variable-name">temperature</span>=<span class="org-py-number">0</span>, <span class="org-comment"># this is the degree of randomness of the model's output</span>
    )
    <span class="org-keyword">return</span> response.choices[<span class="org-py-number">0</span>].message[<span class="org-string">"content"</span>]

<span class="org-py-def-class">def</span> <span class="org-function-name">get_completion_from_messages</span>(messages, <span class="org-py-variable-name">model</span>=<span class="org-string">"gpt-3.5-turbo"</span>, <span class="org-py-variable-name">temperature</span>=<span class="org-py-number">0</span>):
    <span class="org-py-variable-name">response</span> = openai.ChatCompletion.create(
        <span class="org-py-variable-name">model</span>=model,
        <span class="org-py-variable-name">messages</span>=messages,
        <span class="org-py-variable-name">temperature</span>=temperature, <span class="org-comment"># this is the degree of randomness of the model's output</span>
    )
<span class="org-comment-delimiter">#     </span><span class="org-comment">print(str(response.choices[0].message))</span>
    <span class="org-keyword">return</span> response.choices[<span class="org-py-number">0</span>].message[<span class="org-string">"content"</span>]
</pre>
</div>

<hr />

<p>
常见技巧有下面这些：
</p>

<p>
<b><b>将文字圈定起来</b></b>
</p>

<p>
可以使用这些任意分隔符 ```, """, &lt; &gt;, \&lt;tag\&gt;, \&lt;/tag\&gt;.
</p>

<pre class="example" id="org00ea85b">
the TEXT is delimited by ```

TEXT: ```{text}```
</pre>

<p>
<b><b>生成格式</b></b>
</p>

<pre class="example" id="org7d3d458">
Provide them in JSON format with the following keys:
book_id, title, author, genre.

Use the following format:
Text: &lt;text to summarize&gt;
Summary: &lt;summary&gt;
Translation: &lt;summary translation&gt;
Names: &lt;list of names in Italian summary&gt;
Output JSON: &lt;json with summary and num_names&gt;
</pre>

<p>
<b><b>条件判断</b></b>
</p>

<pre class="example" id="orgcdb1104">
If it contains a sequence of instructions, then
</pre>

<p>
<b><b>场景模拟</b></b>
</p>

<pre class="example" id="org72cb8c1">
Your task is to answer in a consistent style.

&lt;child&gt;: Teach me about patience.

&lt;grandparent&gt;: The river that carves the deepest \
valley flows from a modest spring; the \
grandest symphony originates from a single note; \
the most intricate tapestry begins with a solitary thread.

&lt;child&gt;: Teach me about resilience.
</pre>

<p>
<b><b>chatbot</b></b>
</p>

<p>
这个可以设置
</p>
<ul class="org-ul">
<li>system: 告诉chatgpt背景</li>
<li>assitant: assitant之前的话</li>
<li>user: 用户的回答</li>
</ul>

<p>
然后告诉chatgpt之前完整的对话是什么样子的
</p>

<pre class="example" id="org7e20a91">
messages =  [
{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},
{'role':'user', 'content':'tell me a joke'},
{'role':'assistant', 'content':'Why did the chicken cross the road'},
{'role':'user', 'content':'I don\'t know'}  ]

response = get_completion_from_messages(messages, temperature=0.2)
print(response)

&gt; To get to the other side, good sir!
</pre>

<p>
<b><b>长篇内容</b></b>
</p>

<p>
将长篇内容拆分成为多段，并且告诉gpt有这么多段。
</p>

<pre class="example" id="orga38e673">
You are LongTextAnalyzerGPT. I will submit you a long text divided in 35 parts.

Each part will start by Part X. After each part I submit, ask me for the next part. Don't do any analysis before all the parts are submitted.

Part 1. XXX
</pre>

<p>
<b><b>few-shot learning</b></b>
</p>

<p>
在内容里面提供几个参考实例，这样可以现场学习。
</p>

<pre class="example" id="org786a2a2">
Suggest three names for an animal that is a superhero.

Animal: Cat
Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline
Animal: Dog
Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot
Animal: Horse
Names:
</pre>
</div>
<div id="content"><!-- DISQUS BEGIN --><div id="disqus_thread"></div><script>/***  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/var disqus_config = function () {this.page.url = 'https://dirtysalt.github.io/html/chatgpt-prompt-engineering-for-developers.html';this.page.identifier = 'chatgpt-prompt-engineering-for-developers.html';};(function() {var d = document, s = d.createElement('script');s.src = 'https://dirlt.disqus.com/embed.js';s.setAttribute('data-timestamp', +new Date());(d.head || d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><!-- DISQUS END --></div></body>
</html>
